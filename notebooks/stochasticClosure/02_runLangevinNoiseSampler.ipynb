{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f401d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import deepRD\n",
    "from deepRD.diffusionIntegrators import langevinNoiseSampler, langevin\n",
    "from deepRD.potentials import harmonic\n",
    "from deepRD.noiseSampler import noiseSampler\n",
    "from deepRD.noiseSampler import binnedData\n",
    "import deepRD.tools.trajectoryTools as trajectoryTools\n",
    "matplotlib.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0430108",
   "metadata": {},
   "outputs": [],
   "source": [
    "localDataDirectory = './data/'\n",
    "numSimulations = 100 #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e774db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load binning sampling models\n",
    "binnedDataFilename = localDataDirectory + 'qiBinnedData.pickle'\n",
    "#binnedDataFilename = localDataDirectory + 'riBinnedData.pickle'\n",
    "dataOnBins = pickle.load(open(binnedDataFilename, \"rb\" ))\n",
    "parameters = dataOnBins.parameterDictionary\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646917ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define particle list\n",
    "D = parameters['D']\n",
    "#position = [0,0,0]\n",
    "#velocity = [0,0,0]\n",
    "mass =  parameters['mass']\n",
    "#particle1 = deepRD.particle(position, D, velocity, mass)\n",
    "#particleList = deepRD.particleList([particle1])\n",
    "#position = position = np.array([boxsize*random.random()-0.5*boxsize,\n",
    "#                                    boxsize*random.random()-0.5*boxsize,\n",
    "#                                    boxsize*random.random()-0.5*boxsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define noise sampler\n",
    "#nSampler = noiseSampler()\n",
    "nSampler = noiseSampler(dataOnBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define external potential\n",
    "kconstant = 0.3\n",
    "harmonicPotential = harmonic(kconstant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define integrator\n",
    "#dt = binnedData.lagTimesteps * parameters['dt'] * parameters['stride'] #wrong\n",
    "dt = parameters['dt']\n",
    "integratorStride = 50 #5\n",
    "tfinal = 1000 #10000 #0.5 #1 #1000 #100 #10000 #100000\n",
    "KbT = parameters['KbT']\n",
    "boxsize = parameters['boxsize']\n",
    "#integType = \"ABOBA\"\n",
    "equilibrationSteps = 10000# 50000 #10000 #2000\n",
    "diffIntegrator = langevinNoiseSampler(dt, integratorStride, tfinal, nSampler, KbT, \n",
    "                                      boxsize, equilibrationSteps = equilibrationSteps)\n",
    "#diffIntegrator = langevin(dt, integratorStride, tfinal, KbT, boxsize, equilibrationSteps = equilibrationSteps)\n",
    "diffIntegrator.setExternalPotential(harmonicPotential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "particleIndex = 0\n",
    "xpos = np.empty(0)\n",
    "ypos = np.empty(0)\n",
    "zpos = np.empty(0)\n",
    "xvel = np.empty(0)\n",
    "yvel = np.empty(0)\n",
    "zvel = np.empty(0)\n",
    "trajs = []\n",
    "for i in range(numSimulations):\n",
    "    print(\"Simulation \", i+1)\n",
    "    position = [0,0,0] #np.array([boxsize*random.random()-0.5*boxsize,boxsize*random.random()-0.5*boxsize,boxsize*random.random()-0.5*boxsize])\n",
    "    velocity = [0,0,0]\n",
    "    particle1 = deepRD.particle(position, D, velocity, mass)\n",
    "    particleList = deepRD.particleList([particle1])\n",
    "    t, X, V = diffIntegrator.propagate(particleList)\n",
    "    traj = trajectoryTools.convert2trajectory(t,[X,V])\n",
    "    trajs.append(traj)\n",
    "    xpos = np.concatenate((xpos, X[:,particleIndex,0]))\n",
    "    ypos = np.concatenate((ypos, X[:,particleIndex,1]))\n",
    "    zpos = np.concatenate((zpos, X[:,particleIndex,2]))\n",
    "    xvel = np.concatenate((xvel, V[:,particleIndex,0]))\n",
    "    yvel = np.concatenate((yvel, V[:,particleIndex,1]))\n",
    "    zvel = np.concatenate((zvel, V[:,particleIndex,2]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbins=50\n",
    "#averagepos = (np.array(xpos)+np.array(ypos)+np.array(zpos))/3.0\n",
    "#plt.hist(averagepos, bins = numbins, density= True, alpha =0.3)\n",
    "plt.hist(xpos, bins = numbins, density= True, alpha=0.5, label='x')\n",
    "plt.hist(ypos, bins = numbins, density= True, alpha=0.5, label='y')\n",
    "plt.hist(zpos, bins = numbins, density= True, alpha=0.5, label='z')\n",
    "plt.legend()\n",
    "#plt.xlim([-0.15,0.15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec07125",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5bde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbins=50\n",
    "#averagepos = (np.array(xpos)+np.array(ypos)+np.array(zpos))/3.0\n",
    "#plt.hist(averagepos, bins = numbins, density= True, #alpha =0.3)\n",
    "plt.hist(xvel, bins = numbins, density= True, alpha=0.5, label='x')\n",
    "plt.hist(yvel, bins = numbins, density= True, alpha=0.5, label='y')\n",
    "plt.hist(zvel, bins = numbins, density= True, alpha=0.5, label='z')\n",
    "plt.legend()\n",
    "#plt.xlim([-0.15,0.15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8ad7e",
   "metadata": {},
   "source": [
    "## Load one benchmark trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cad16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepRD.tools.trajectoryTools as trajectoryTools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parentDirectory = os.environ.get('MSMRD') + '/data/MoriZwanzig/benchmark_onetrajectory/'\n",
    "fnamebase = parentDirectory + 'simMoriZwanzig_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68730fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trajectory data from h5 files (only of distinguished particle)\n",
    "trajs_ref = []\n",
    "print(\"Loading data ...\")\n",
    "for i in range(numSimulations):\n",
    "    traj = trajectoryTools.loadTrajectory(fnamebase, i)\n",
    "    trajs_ref.append(traj)    \n",
    "    print(\"File \", i+1, \" of \", numSimulations, \" done.\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf0d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions\n",
    "xpos_ref = []\n",
    "ypos_ref = []\n",
    "zpos_ref = []\n",
    "xvel_ref = []\n",
    "yvel_ref = []\n",
    "zvel_ref = []\n",
    "numbins = 50\n",
    "for traj in trajs_ref:\n",
    "    for i in range(len(traj)):\n",
    "        xpos_ref.append(traj[i][1])\n",
    "        ypos_ref.append(traj[i][2])\n",
    "        zpos_ref.append(traj[i][3])\n",
    "        xvel_ref.append(traj[i][4])\n",
    "        yvel_ref.append(traj[i][5])\n",
    "        zvel_ref.append(traj[i][6])\n",
    "#averagepos = (np.array(xpos_ref)+np.array(ypos_ref)+np.array(zpos_ref))/3.0\n",
    "#plt.hist(averagepos, bins = numbins, density= True, alpha =0.3)\n",
    "plt.hist(np.array(xpos_ref), bins = numbins, density= True, alpha=0.5, label='x')\n",
    "plt.hist(np.array(ypos_ref), bins = numbins, density= True, alpha=0.5, label='y')\n",
    "plt.hist(np.array(zpos_ref), bins = numbins, density= True, alpha=0.5, label='z')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b990353",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(xvel_ref), bins = numbins, density= True, alpha=0.5, label='x')\n",
    "plt.hist(np.array(yvel_ref), bins = numbins, density= True, alpha=0.5, label='y')\n",
    "plt.hist(np.array(zvel_ref), bins = numbins, density= True, alpha=0.5, label='z')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc7626",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a11ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbins=50\n",
    "plt.hist(np.array(yvel), bins = numbins, density= True, alpha=0.5, label='reduced')\n",
    "plt.hist(np.array(yvel_ref), bins = numbins, density= True, alpha=0.5, label='benchmark')\n",
    "density = stats.kde.gaussian_kde(xvel)\n",
    "#vv = np.arange(-1., 1, .02)\n",
    "#plt.plot(vv, density(vv))\n",
    "plt.legend()\n",
    "plt.xlabel(\"velocity\")\n",
    "plt.ylabel(\"velocity distribution\")\n",
    "#plt.show()\n",
    "plt.savefig(\"velocity_test.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ffc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbins=50\n",
    "#plt.hist(np.array(zpos), bins = numbins, density= True, alpha=0.5, label='reduced')\n",
    "plt.hist(np.array(zpos_ref), bins = numbins, density= True, alpha=0.5, label='benchmark')\n",
    "plt.legend()\n",
    "plt.xlabel(\"position\")\n",
    "plt.ylabel(\"position distribution\")\n",
    "plt.xlim([-5,5])\n",
    "plt.show()\n",
    "#plt.savefig(\"position_test.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b327b0",
   "metadata": {},
   "source": [
    "## Calculate autocorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate moments\n",
    "def calculateMean(trajs, var = 'position'):\n",
    "    if var == 'position':\n",
    "        index = 1\n",
    "    elif var == 'velocity':\n",
    "        index = 4\n",
    "    meanPosition = np.zeros(3)\n",
    "    totalSamples = 0\n",
    "    for traj in trajs:\n",
    "        for i in range(len(traj)):\n",
    "            meanPosition += traj[i][index:index+3]\n",
    "        totalSamples += len(traj)\n",
    "    meanPosition = meanPosition/totalSamples\n",
    "    return meanPosition\n",
    "\n",
    "def calculateVariance(trajs, var = 'position', mean = None):\n",
    "    if var == 'position':\n",
    "        index = 1\n",
    "    elif var == 'velocity':\n",
    "        index = 4\n",
    "    if mean.any() == None:\n",
    "        mean = calculateMean(trajs)\n",
    "    variance = np.zeros(3)\n",
    "    totalSamples = 0\n",
    "    for traj in trajs:\n",
    "        for i in range(len(traj)):\n",
    "            devFromMean = traj[i][index:index+3] - mean\n",
    "            variance += devFromMean*devFromMean\n",
    "        totalSamples += len(traj)\n",
    "    variance = variance/totalSamples\n",
    "    return variance\n",
    "\n",
    "def calculateStdDev(trajs, var = 'position', mean = None):\n",
    "    variance = calculateVariance(trajs, var, mean)\n",
    "    stddev = np.sqrt(variance)\n",
    "    return stddev\n",
    "\n",
    "def calculateAutoCorrelation(trajs, lagtimesteps, stride = 1, var = 'position', mean = None, variance = None):\n",
    "    if var == 'position':\n",
    "        index = 1\n",
    "    elif var == 'velocity':\n",
    "        index = 4\n",
    "    if mean.any() == None:\n",
    "        mean = calculateMean(trajs)\n",
    "    if variance.any() == None:\n",
    "        variance = calculateVariance(trajs, mean)\n",
    "    totalSamples = 0\n",
    "    AC = 0.0\n",
    "    for traj in trajs:\n",
    "        for i in range(len(traj)-lagtimesteps*stride):\n",
    "            devFromMean = traj[i][index:index+3] - mean\n",
    "            devFromMean2 = traj[i + lagtimesteps*stride][index:index+3] - mean\n",
    "            AC += np.dot(devFromMean, devFromMean2)\n",
    "        totalSamples += len(traj)\n",
    "    AC = AC/totalSamples\n",
    "    AC = AC/variance\n",
    "    return AC\n",
    "\n",
    "def calculateAutoCorrelationFunction(trajs, lagtimesteps, stride = 1, var = 'position'):\n",
    "    ACF = []\n",
    "    mean = calculateMean(trajs, var)\n",
    "    # Calculate one dimensional variance\n",
    "    if var == 'position':\n",
    "        index = 1\n",
    "    elif var == 'velocity':\n",
    "        index = 4\n",
    "    variance = 0\n",
    "    totalSamples = 0\n",
    "    for traj in trajs:\n",
    "        for i in range(len(traj)):\n",
    "            devFromMean = traj[i][index:index+3] - mean\n",
    "            variance += np.dot(devFromMean,devFromMean)\n",
    "        totalSamples += len(traj)\n",
    "    variance = variance/totalSamples\n",
    "    for lagtime in range(lagtimesteps):\n",
    "        ACF.append(calculateAutoCorrelation(trajs, lagtime, stride, var, mean, variance))\n",
    "        print('Computing ACF:', 100*(lagtime+1)/lagtimesteps , '% complete   ', end=\"\\r\")\n",
    "    ACF = np.array(ACF)\n",
    "    return ACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6925b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['position', 'velocity']\n",
    "lagtimesteps = 40\n",
    "strides = [50,1]\n",
    "ACF = [None]*2\n",
    "ACF_ref = [None]*2\n",
    "for i, var in enumerate(variables):\n",
    "    mean = calculateMean(trajs, var)\n",
    "    mean_ref = calculateMean(trajs_ref, var)\n",
    "    variance = calculateVariance(trajs, var, mean)\n",
    "    variance_ref = calculateVariance(trajs_ref, var, mean_ref)\n",
    "    ACF[i] = calculateAutoCorrelationFunction(trajs, lagtimesteps, strides[i], var)\n",
    "    ACF_ref[i] = calculateAutoCorrelationFunction(trajs_ref, lagtimesteps, strides[i], var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "time = dt*integratorStride*strides[index]*np.linspace(1,lagtimesteps,lagtimesteps)\n",
    "plt.plot(time, ACF[index], 'xk', label = 'reduced model')\n",
    "plt.plot(time, ACF_ref[index], '-k', label = 'benchmark')\n",
    "plt.xlabel('time(ns)')\n",
    "plt.ylabel(variables[index] + ' autocorrelation')\n",
    "plt.legend()\n",
    "#plt.xlim([0,1500])\n",
    "plt.savefig(variables[index]+ ' autocorrelation.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7ae3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
