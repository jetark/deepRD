{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428946ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from deepRD.noiseSampler import binnedData\n",
    "import deepRD.tools.trajectoryTools as trajectoryTools\n",
    "import deepRD.tools.analysisTools as analysisTools\n",
    "matplotlib.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark data folder\n",
    "parentDirectory = os.environ.get('MSMRD') + '/data/MoriZwanzig/bistable/old/benchmarkComparison/'\n",
    "benchmarkfnamebase = parentDirectory + 'simMoriZwanzig_'\n",
    "# Reduced models data folders\n",
    "localDataDirectory = '../../data/stochasticClosure/bistable/benchmarkReduced'\n",
    "numModels = 8\n",
    "redModelfnamebase = [localDataDirectory]*numModels\n",
    "redModelfnamebase[0] += '_ri/simMoriZwanzigReduced_'\n",
    "redModelfnamebase[1] += '_ririm/simMoriZwanzigReduced_'\n",
    "redModelfnamebase[2] += '_qi/simMoriZwanzigReduced_'\n",
    "redModelfnamebase[3] += '_qiri/simMoriZwanzigReduced_'\n",
    "redModelfnamebase[4] += '_qiririm/simMoriZwanzigReduced_'\n",
    "redModelfnamebase[5] += '_pi/simMoriZwanzigReduced_'\n",
    "redModelfnamebase[6] += '_piri/simMoriZwanzigReduced_'\n",
    "redModelfnamebase[7] += '_piririm/simMoriZwanzigReduced_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5754d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read relevant parameters\n",
    "parameterDictionary = analysisTools.readParameters(parentDirectory + \"parameters\")\n",
    "numSimulations = 6 #10 #20 #parameterDictionary['numFiles']\n",
    "dt = parameterDictionary['dt'] \n",
    "integratorStride = parameterDictionary['stride']\n",
    "totalTimeSteps = parameterDictionary['timesteps'] \n",
    "boxsize = parameterDictionary['boxsize']\n",
    "boundaryType = parameterDictionary['boundaryType']\n",
    "parameterDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7c51f",
   "metadata": {},
   "source": [
    "## Load benchmark and reduced model trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmark trajectory data from h5 files (only of distinguished particle)\n",
    "trajs_ref = []\n",
    "print(\"Loading benchmark data ...\")\n",
    "for i in range(numSimulations):\n",
    "    traj = trajectoryTools.loadTrajectory(benchmarkfnamebase, i)\n",
    "    trajs_ref.append(traj)    \n",
    "    print(\"File \", i+1, \" of \", numSimulations, \" done.\", end=\"\\r\")\n",
    "print(\"Benchmark data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reduced model trajectory data from h5 files (only of distinguished particle)\n",
    "allTrajs = [None]*numModels\n",
    "print(\"Loading reduced models data ...\")\n",
    "for i in range(numModels):\n",
    "    try:\n",
    "        iTraj = []\n",
    "        for j in range(numSimulations):\n",
    "            traj = trajectoryTools.loadTrajectory(redModelfnamebase[i], j)\n",
    "            iTraj.append(traj)\n",
    "            print(\"File \", i+1, \" of \", numSimulations, \" done.\", end=\"\\r\")\n",
    "        allTrajs[i] = iTraj\n",
    "    except:\n",
    "        continue\n",
    "print(\"Reduced models data loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe07de",
   "metadata": {},
   "source": [
    "## Kernel density estimation from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which reduced model to compare (just uncomment one)\n",
    "conditionedOn = 'piri' #Possibilities 'qi', 'ri', 'qiri', 'qiririm'\n",
    "\n",
    "if conditionedOn == 'ri':\n",
    "    trajs = allTrajs[0]\n",
    "    texlabel = r'$(r_{i+1}|r_i)$'\n",
    "elif conditionedOn == 'ririm':\n",
    "    trajs = allTrajs[1] \n",
    "    texlabel = r'$(r_{i+1}|r_i,r_{i-1})$'\n",
    "elif conditionedOn == 'qi':\n",
    "    trajs = allTrajs[2] \n",
    "    texlabel = r'$(r_{i+1}|x_i)$'\n",
    "elif conditionedOn == 'qiri':\n",
    "    trajs = allTrajs[3] \n",
    "    texlabel = r'$(r_{i+1}|x_i,r_i)$'\n",
    "elif conditionedOn == 'qiririm':\n",
    "    trajs = allTrajs[4] \n",
    "    texlabel = r'$(r_{i+1}|x_i,r_i,r_{i-1})$'\n",
    "elif conditionedOn == 'pi':\n",
    "    trajs = allTrajs[5] \n",
    "    texlabel = r'$(r_{i+1}|v_i)$'\n",
    "elif conditionedOn == 'piri':\n",
    "    trajs = allTrajs[6] \n",
    "    texlabel = r'$(r_{i+1}|v_i,r_i)$'\n",
    "elif conditionedOn == 'piririm':\n",
    "    trajs = allTrajs[7]\n",
    "    texlabel = r'$(r_{i+1}|v_i,r_i,r_{i-1})$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ffade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract variables to plot from tajectories\n",
    "position = trajectoryTools.extractVariableFromTrajectory(trajs, variableIndex = [1,4])\n",
    "velocity = trajectoryTools.extractVariableFromTrajectory(trajs, variableIndex = [4,7])\n",
    "position_ref = trajectoryTools.extractVariableFromTrajectory(trajs_ref, variableIndex = [1,4])\n",
    "velocity_ref = trajectoryTools.extractVariableFromTrajectory(trajs_ref, variableIndex = [4,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Obtain bandwidth for kernel density estimation through cross validation\n",
    "numsamples = 50000\n",
    "crossValidation = False\n",
    "if crossValidation:\n",
    "    # Sample random points from original data (both positions and velocities)\n",
    "    idx = np.random.randint(len(position_ref), size=numsamples)\n",
    "    sampled_positions = position_ref[idx,:]\n",
    "    sampled_velocities = velocity_ref[idx,:]\n",
    "    \n",
    "    # Run cross validations for positions\n",
    "    gridPos = GridSearchCV(KernelDensity(),\n",
    "                        {'bandwidth': np.linspace(0.1, 1.0, 31)},\n",
    "                        cv=5,  # 5-fold cross-validation\n",
    "                        verbose=2)\n",
    "    gridPos.fit(sampled_positions)\n",
    "    print(gridPos.best_params_)\n",
    "    print(gridPos.best_estimator_)\n",
    "    \n",
    "    # Run cross validations for velocities\n",
    "    gridVel = GridSearchCV(KernelDensity(),\n",
    "                        {'bandwidth': np.linspace(0.01, 0.2, 31)},\n",
    "                        cv=5,  # 5-fold cross-validation\n",
    "                        verbose=2)\n",
    "    gridVel.fit(sampled_velocities) #(sampled_positions) \n",
    "    print(gridVel.best_params_)\n",
    "    print(gridVel.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c11594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the densities using Gaussian kernel density estimation\n",
    "bandwidthPos = 0.190 # Obtained through cross-validation 0.19(Main) but also 0.22 and 0.28 #0.77 #0.2\n",
    "bandwidthVel = 0.036 # Obtained through cross-validation 0.036(Main) but also 0.1\n",
    "# Use \"epanechnikov\" for fast tests, \"gaussian\" for final plots\n",
    "kernelType = \"gaussian\" #\"epanechnikov\" # \"epanechnikov\", \"tophat\" \"gaussian\" # Sample requires Guassian/tophat\n",
    "rtol=1E-3 # Default value zero, sacrifices minor accuracy for faster computation\n",
    "kdePosition = KernelDensity(kernel=kernelType, bandwidth=bandwidthPos, rtol=rtol).fit(position)\n",
    "kdePosition_ref = KernelDensity(kernel=kernelType, bandwidth=bandwidthPos, rtol=rtol).fit(position_ref)\n",
    "kdeVelocity = KernelDensity(kernel=kernelType, bandwidth=bandwidthVel, rtol=rtol).fit(velocity)\n",
    "kdeVelocity_ref = KernelDensity(kernel=kernelType, bandwidth=bandwidthVel, rtol=rtol).fit(velocity_ref)\n",
    "def calculateKernelDensity(x, variable = 'position_ref'):\n",
    "    if variable == 'position':\n",
    "        log_dens = kdePosition.score_samples(x)\n",
    "    elif variable == 'position_ref':\n",
    "        log_dens = kdePosition_ref.score_samples(x)\n",
    "    elif variable == 'velocity':\n",
    "        log_dens = kdeVelocity.score_samples(x)\n",
    "    elif variable == 'velocity_ref':\n",
    "        log_dens = kdeVelocity_ref.score_samples(x)\n",
    "    return np.exp(log_dens)\n",
    "\n",
    "def sampleKernelDensity(numSamples, variable = 'position_ref'):\n",
    "    ''' Only available for kernel density estimation using gaussian or tophat'''\n",
    "    if variable == 'position':\n",
    "        return kdePosition.sample(numSamples)\n",
    "    elif variable == 'position_ref':\n",
    "        return kdePosition_ref.sample(numSamples)\n",
    "    elif variable == 'velocity':\n",
    "        return kdeVelocity.sample(numSamples)\n",
    "    elif variable == 'velocity_ref':\n",
    "        return kdeVelocity_ref.sample(numSamples)\n",
    "    \n",
    "# Sample 3D values from estimated reference density. It can only sample \n",
    "# if Gaussian or tophat kernels are being used\n",
    "#numsamples = 50000\n",
    "#values = sampleKernelDensity(numsamples, variable)\n",
    "#values_ref = sampleKernelDensity(numsamples, variable + '_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ba3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate kernel density output for a certain one dimensional cut going through the origin.\n",
    "\n",
    "# Obtain x, y, or z cut of the distribution\n",
    "xxPos = np.arange(-4,4,0.1)\n",
    "xxVel = np.arange(-0.6,0.6,0.015)\n",
    "ww = np.zeros(len(xxPos))\n",
    "ww2 = np.zeros(len(xxVel))\n",
    "xyzcutPos = [None]*3\n",
    "xyzcutVel = [None]*3\n",
    "distributionPos = [None]*3\n",
    "distributionPos_ref = [None]*3 \n",
    "distributionVel = [None]*3\n",
    "distributionVel_ref = [None]*3\n",
    "xlabel = [r'$x$', r'$y$', r'$z$']\n",
    "zerolabel = [r'$y=z=0$', r'$x=z=0$', r'$x=y=0$']\n",
    "\n",
    "# Calculate distributions for xcut (y=z=0)\n",
    "xyzcutPos[0] = np.array(list(zip(xxPos,ww,ww))).reshape(-1, 3)\n",
    "xyzcutVel[0] = np.array(list(zip(xxVel,ww2,ww2))).reshape(-1, 3)\n",
    "distributionPos[0] = calculateKernelDensity(xyzcutPos[0], 'position')\n",
    "distributionPos_ref[0] = calculateKernelDensity(xyzcutPos[0], 'position_ref')\n",
    "distributionVel[0] = calculateKernelDensity(xyzcutVel[0], 'velocity')\n",
    "distributionVel_ref[0] = calculateKernelDensity(xyzcutVel[0], 'velocity_ref')\n",
    "print(\"Calculations of x-cut distributions finished.\")\n",
    "\n",
    "# Calculate distributions for ycut (x=z=0)\n",
    "xyzcutPos[1] = np.array(list(zip(ww,xxPos,ww))).reshape(-1, 3)\n",
    "xyzcutVel[1] = np.array(list(zip(ww2,xxVel,ww2))).reshape(-1, 3)\n",
    "distributionPos[1] = calculateKernelDensity(xyzcutPos[1], 'position')\n",
    "distributionPos_ref[1] = calculateKernelDensity(xyzcutPos[1], 'position_ref')\n",
    "distributionVel[1] = calculateKernelDensity(xyzcutVel[1], 'velocity')\n",
    "distributionVel_ref[1] = calculateKernelDensity(xyzcutVel[1], 'velocity_ref')\n",
    "print(\"Calculations of y-cut distributions finished.\")\n",
    "\n",
    "# Calculate distributions for zcut (x=y=0)\n",
    "xyzcutPos[2] = np.array(list(zip(ww,ww,xxPos))).reshape(-1, 3)\n",
    "xyzcutVel[2] = np.array(list(zip(ww2,ww2,xxVel))).reshape(-1, 3)\n",
    "distributionPos[2] = calculateKernelDensity(xyzcutPos[2], 'position')\n",
    "distributionPos_ref[2] = calculateKernelDensity(xyzcutPos[2], 'position_ref')\n",
    "distributionVel[2] = calculateKernelDensity(xyzcutVel[2], 'velocity')\n",
    "distributionVel_ref[2] = calculateKernelDensity(xyzcutVel[2], 'velocity_ref')\n",
    "print(\"Calculations of z-cut distributions finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7156c",
   "metadata": {},
   "source": [
    "## Distribution plots comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb29307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution comparisons\n",
    "\n",
    "# Create plot\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.2)\n",
    "ax1, ax2 = gs.subplots() #sharey='row')\n",
    "\n",
    "# Plot position distribution\n",
    "for i in range(3):\n",
    "    ax1[i].plot(xxPos,distributionPos_ref[i], '-k', lw = 0.5)\n",
    "    ax1[i].fill_between(xxPos,distributionPos_ref[i], color='dodgerblue', alpha = 0.15, label = \"benchmark\")\n",
    "    ax1[i].plot(xxPos,distributionPos[i], 'xk', label = 'reduced ' + texlabel)\n",
    "    #ax1[i].set_xlim((-4,4))\n",
    "    ax1[i].set_ylim((0,None))\n",
    "    ax1[i].set_xlabel(xlabel[i] + '-position')\n",
    "    if i==0:\n",
    "        ax1[i].yaxis.set_ticks(np.arange(0,0.1,0.02)) \n",
    "    else:\n",
    "        ax1[i].yaxis.set_ticks(np.arange(0,0.03,0.01)) \n",
    "    \n",
    "\n",
    "    # Plot velocity distribution\n",
    "    ax2[i].plot(xxVel,distributionVel_ref[i], '-k', lw = 0.5)\n",
    "    ax2[i].fill_between(xxVel,distributionVel_ref[i], color='dodgerblue', alpha = 0.15, label = \"benchmark\")\n",
    "    ax2[i].plot(xxVel,distributionVel[i], 'xk', label = 'reduced ' + texlabel)\n",
    "    #ax2[i].set_xlim((-0.6,0.6))\n",
    "    ax2[i].set_ylim((0,None))\n",
    "    ax2[i].set_xlabel(xlabel[i] + '-velocity' + '\\n('+ zerolabel[i] +')')\n",
    "    ax2[i].xaxis.set_ticks(np.arange(-0.5,0.6,0.5)) \n",
    "    #ax2[i].yaxis.set_ticks(np.arange(0,1.5,0.5)) \n",
    "\n",
    "ax1[2].legend(bbox_to_anchor=(0.6, 0., 0.5, 1.0), framealpha=1.0)\n",
    "    \n",
    "# displaying plot\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('distributions_comparison_bistable_'+ conditionedOn +'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x-position distribution vs samples from original data\n",
    "\n",
    "# Create plot\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(8,6), nrows=2, sharex=True)\n",
    "\n",
    "# Plot x-position distribution\n",
    "ax1.plot(xxPos,distributionPos_ref[0], '-k', lw = 0.5)\n",
    "ax1.fill_between(xxPos,distributionPos_ref[0], color='dodgerblue', alpha = 0.15, label = \"benchmark (kde)\")\n",
    "#ax1.plot(xx,distributionPos[0], 'xk', label = 'reduced ' + texlabel)\n",
    "ax1.set_ylim((0,0.11)) #None))\n",
    "ax1.yaxis.set_ticks(np.arange(0,0.15,0.05)) \n",
    "ax1.legend(bbox_to_anchor=(0.5, 0., 0.5, 1.02)) #, framealpha=1.0, borderpad=0.2)\n",
    "\n",
    "# Plot velocity distribution\n",
    "numsamples = 50000\n",
    "idx = np.random.randint(len(position_ref), size=numsamples)\n",
    "sampledPosRef = position_ref[idx,:]\n",
    "sampledVelRef = velocity_ref[idx,:]\n",
    "\n",
    "ax2.scatter(sampledPosRef[:,0],sampledPosRef[:,1], marker='o', s=0.1,label='random data samples')\n",
    "\n",
    "ax2.set_xlabel('position ' + xlabel[0])\n",
    "ax2.set_ylabel(r'$y$')\n",
    "ax2.set_xlim([-4,4])\n",
    "ax2.set_ylim([-1.5,1.5])\n",
    "ax2.xaxis.set_ticks(np.arange(-4,5,2)) \n",
    "ax2.yaxis.set_ticks(np.arange(-1,2,1)) \n",
    "ax2.legend(loc=\"upper right\", markerscale=20, borderpad=0.1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "#plt.savefig('kernel_density_estimation.pdf')\n",
    "#plt.savefig('distributions_n_sampleddata_bistable_'+ conditionedOn +'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples from original data\n",
    "numsamples = 50000\n",
    "idx = np.random.randint(len(position_ref), size=numsamples)\n",
    "#subsampleValues = position_ref[idx,:]\n",
    "subsampleValues = velocity_ref[idx,:]\n",
    "\n",
    "\n",
    "# Uncomment to plot samples from benchmark kernel density\n",
    "#subsampleValues = values_ref[0:numsamples]\n",
    "\n",
    "# Uncomment to plot samples from reduced model kernel density\n",
    "#subsampleValues = values_ref[0:numsamples]\n",
    "\n",
    "  \n",
    "# creating figures\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "  \n",
    "# creating the heatmap\n",
    "img = ax.scatter(subsampleValues[:,0],subsampleValues[:,1],subsampleValues[:,2], marker='o',s=1)\n",
    "  \n",
    "# adding title and labels\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "#ax.set_xlim([-4,4])\n",
    "#ax.set_ylim([-4,4])\n",
    "#ax.set_zlim([-4,4])\n",
    "  \n",
    "# displaying plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50353375",
   "metadata": {},
   "source": [
    "## Plot auto-correlation functions comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses only a subset (mtrajs) of the total trajectories, since computing them with all is very slow\n",
    "variables = ['position', 'velocity']\n",
    "lagtimesteps = [40,40]\n",
    "mtrajs = 1\n",
    "strides = [200,5] #[30,1]\n",
    "ACF = [None]*2\n",
    "ACF_ref = [None]*2\n",
    "for i, var in enumerate(variables):\n",
    "    #mean = trajectoryTools.calculateMean(trajs[0:mtrajs], var)\n",
    "    #mean_ref = trajectoryTools.calculateMean(trajs_ref[0:mtrajs], var)\n",
    "    #variance = trajectoryTools.calculateVariance(trajs[0:mtrajs], var, mean)\n",
    "    #variance_ref = trajectoryTools.calculateVariance(trajs_ref[0:mtrajs], var, mean_ref)\n",
    "    ACF[i] = trajectoryTools.calculateAutoCorrelationFunction(trajs[0:mtrajs], lagtimesteps[i], strides[i], var)\n",
    "    ACF_ref[i] = trajectoryTools.calculateAutoCorrelationFunction(trajs_ref[0:mtrajs], lagtimesteps[i], strides[i], var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "time = dt*integratorStride*strides[index]*np.linspace(1,lagtimesteps[index],lagtimesteps[index])\n",
    "plt.plot(time/1000, ACF[index], 'xk', label = 'reduced ' + texlabel)\n",
    "plt.plot(time/1000, ACF_ref[index], '-k', label = 'benchmark')\n",
    "plt.xlabel('time ' +r'$(\\mu s)$')\n",
    "plt.ylabel(variables[index] + ' autocorrelation')\n",
    "plt.legend()\n",
    "#plt.xlim([0,1500])\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "#plt.savefig(variables[index]+ '_autocorrelation_bistable_'+ conditionedOn +'.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "time = dt*integratorStride*strides[index]*np.linspace(1,lagtimesteps[index],lagtimesteps[index])\n",
    "plt.plot(time, ACF[index], 'xk', label = 'reduced ' + texlabel)\n",
    "plt.plot(time, ACF_ref[index], '-k', label = 'benchmark')\n",
    "plt.xlabel('time ' + r'$(ns)$')\n",
    "plt.ylabel(variables[index] + ' autocorrelation')\n",
    "plt.legend()\n",
    "#plt.xlim([0,1500])\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "#plt.savefig(variables[index]+ '_autocorrelation_bistable_'+ conditionedOn +'.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e581e8",
   "metadata": {},
   "source": [
    "## Plotted projected binned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original trajectory data from h5 files (only of distinguished particle)\n",
    "trajs_original = []\n",
    "fname = os.environ.get('MSMRD') + '/data/MoriZwanzig/bistable/benchmarkComparisonSmallGamma/simMoriZwanzig_'\n",
    "print(\"Loading benchmark data ...\")\n",
    "for i in range(10):\n",
    "    traj = trajectoryTools.loadTrajectory(fname, i)\n",
    "    trajs_original.append(traj)    \n",
    "    print(\"File \", i+1, \" of \", numSimulations, \" done.\", end=\"\\r\")\n",
    "print(\"Benchmark data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exctract aux variables\n",
    "pos_original = trajectoryTools.extractVariableFromTrajectory(trajs_original, variableIndex = [1,4])\n",
    "vel_original = trajectoryTools.extractVariableFromTrajectory(trajs_original, variableIndex = [4,7])\n",
    "raux_original = trajectoryTools.extractVariableFromTrajectory(trajs_original, variableIndex = [8,11])\n",
    "#raux_ref = trajectoryTools.extractVariableFromTrajectory(trajs_ref, variableIndex = [8,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a certain given number of samples randomly\n",
    "numsamples = 25000 #50000\n",
    "#idx = np.random.randint(len(position_ref), size=numsamples)\n",
    "#sampledXminus = position_ref[idx-1,:]\n",
    "#sampledVminus = velocity_ref[idx-1,:]\n",
    "#sampledRminus = raux_ref[idx-1,:]\n",
    "#sampledX = position_ref[idx,:]\n",
    "#sampledV = velocity_ref[idx,:]\n",
    "#sampledR = raux_ref[idx,:]\n",
    "#sampledRplus = raux_ref[idx+1,:]\n",
    "idx = np.random.randint(len(pos_original), size=numsamples)\n",
    "sampledXminus = pos_original[idx-1,:]\n",
    "sampledVminus = vel_original[idx-1,:]\n",
    "sampledRminus = raux_original[idx-1,:]\n",
    "sampledX = pos_original[idx,:]\n",
    "sampledV = vel_original[idx,:]\n",
    "sampledR = raux_original[idx,:]\n",
    "sampledRplus = raux_original[idx+1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f22ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "matplotlib.rc('axes', labelsize=22)\n",
    "\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "gs = fig.add_gridspec(3, 3, wspace=0)\n",
    "ax1, ax2, ax3 = gs.subplots(sharey='row')\n",
    "\n",
    "# Plot distribution projections\n",
    "rplusIndex = 0 # 0,1 or 2 for x,y or z\n",
    "varlabelrplus = [r'$r_{x,i+1}$', r'$r_{i+1}^y$', r'$r_{i+1}^z$']\n",
    "varlabelr = [r'$r_{x,i}$', r'$r_{y,i}$', r'$r_{z,i}$']\n",
    "varlabelx = [r'$x_i$', r'$y_i$', r'$z_i$']\n",
    "varlabelv = [r'$v_{x,i}$', r'$v_{y,i}$', r'$v_{z,i}$']\n",
    "\n",
    "ax1[0].scatter(sampledR[:,0],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "ax1[1].scatter(sampledR[:,1],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "ax1[2].scatter(sampledR[:,2],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "\n",
    "ax2[0].scatter(sampledX[:,0],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "ax2[1].scatter(sampledX[:,1],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "ax2[2].scatter(sampledX[:,2],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "\n",
    "ax3[0].scatter(sampledV[:,0],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "ax3[1].scatter(sampledV[:,1],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "ax3[2].scatter(sampledV[:,2],sampledRplus[:,rplusIndex], marker='o', color='k', s=0.02)\n",
    "\n",
    "for i in range(3):\n",
    "    ax1[i].set_xlabel(varlabelr[i])\n",
    "    ax1[i].set_xlim([-0.04,0.04])\n",
    "    ax1[i].set_ylim([-0.04,0.04])\n",
    "    ax1[i].xaxis.set_ticks(np.arange(-0.03,0.04,0.03)) \n",
    "    \n",
    "    ax2[i].set_xlabel(varlabelx[i])\n",
    "    ax2[i].set_xlim([-4,4])\n",
    "    ax2[i].set_ylim([-0.04,0.04])\n",
    "    ax2[i].xaxis.set_ticks(np.arange(-3,4,3)) \n",
    "    \n",
    "    ax3[i].set_xlabel(varlabelv[i])\n",
    "    ax3[i].set_xlim([-0.5,0.5])\n",
    "    ax3[i].set_ylim([-0.04,0.04])\n",
    "    ax3[i].xaxis.set_ticks(np.arange(-0.4,0.5,0.4)) \n",
    "    \n",
    "    ax1[i].yaxis.set_ticks(np.arange(-0.03,0.04,0.03)) \n",
    "    ax2[i].yaxis.set_ticks(np.arange(-0.03,0.04,0.03)) \n",
    "    ax3[i].yaxis.set_ticks(np.arange(-0.03,0.04,0.03)) \n",
    "\n",
    "ax1[0].set_ylabel(varlabelrplus[rplusIndex])\n",
    "ax2[0].set_ylabel(varlabelrplus[rplusIndex])\n",
    "ax3[0].set_ylabel(varlabelrplus[rplusIndex])\n",
    "\n",
    "plt.subplots_adjust(bottom=-0.5)\n",
    "\n",
    "#ax.legend(loc=\"upper right\", markerscale=20, borderpad=0.1)\n",
    "#plt.savefig('dataHarmonic_projections_plots.pdf', bbox_inches='tight')\n",
    "#plt.savefig('dataHarmonic_projections_plots.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data of one projection\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(sampledR[:,0],sampledRplus[:,0], marker='o', color='k', s=0.02)\n",
    "\n",
    "# Plot binning lines\n",
    "xbins = np.arange(-0.04,0.041,0.005)\n",
    "ymin, ymax = -0.05,0.05\n",
    "for xx in xbins:\n",
    "    ax.plot([xx,xx], [ymin, ymax], '--k', alpha =0.7)\n",
    "\n",
    "ax.set_xlim([-0.04,0.0401])\n",
    "ax.set_ylim([ymin, ymax])\n",
    "ax.set_xlabel(varlabelr[0])\n",
    "ax.set_ylabel(varlabelrplus[0])\n",
    "ax.xaxis.set_ticks(np.arange(-0.04,0.041,0.02)); \n",
    "ax.yaxis.set_ticks(np.arange(-0.03,0.031,0.03)); \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#ax.spines['bottom'].set_visible(False)\n",
    "#ax.spines['left'].set_visible(False)\n",
    "#ax.set_aspect('equal')\n",
    "#plt.savefig('binning_is_winning.pdf', bbox_inches='tight')\n",
    "#plt.savefig('binning_is_winning.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379778d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1206adbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
